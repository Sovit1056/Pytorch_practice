{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17277d2",
   "metadata": {},
   "source": [
    "## pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328eda52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1262, 0.1865, 0.3316],\n",
      "        [0.6599, 0.6927, 0.8326],\n",
      "        [0.4515, 0.8671, 0.0990]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "X = torch.rand(3,3)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f161a534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# creating tensor\n",
    "#scalar\n",
    "\n",
    "scalar= torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d50b5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "036888ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get tensor back as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487f2626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector= torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7267781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "456b8bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fdff2c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix\n",
    "\n",
    "MATRIX= torch.tensor([[7,7],[9,9]])\n",
    "print(MATRIX.shape)\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8a3115af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR= torch.tensor([[[1,2,3],[6,5,4],[9,8,7]]])\n",
    "TENSOR.shape\n",
    "# tensor and matrix are generally represented in uppercase.\n",
    "# If you have: tensor = torch.randn(32, 3, 224, 224) It means: 32 = batch size (32 images): 3 = channels (e.g., RGB): 224 x 224 = height x width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da2cbcb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4284142924.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[154]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mRandom tensor\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7b86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9937, 0.5022, 0.4339, 0.9318, 0.2435, 0.6719, 0.0540, 0.9419, 0.8598,\n",
       "         0.9033],\n",
       "        [0.9770, 0.9738, 0.0026, 0.1747, 0.9306, 0.9824, 0.4155, 0.8703, 0.7518,\n",
       "         0.2544],\n",
       "        [0.6429, 0.9249, 0.5877, 0.7817, 0.8762, 0.0394, 0.6087, 0.8568, 0.7413,\n",
       "         0.8126],\n",
       "        [0.4927, 0.4159, 0.6225, 0.4084, 0.8664, 0.7455, 0.8386, 0.8706, 0.4058,\n",
       "         0.5388],\n",
       "        [0.5928, 0.1475, 0.4368, 0.0446, 0.1447, 0.8610, 0.6943, 0.6800, 0.1531,\n",
       "         0.3395],\n",
       "        [0.3026, 0.1485, 0.1518, 0.6898, 0.2973, 0.4007, 0.1279, 0.4816, 0.0755,\n",
       "         0.4168],\n",
       "        [0.6032, 0.9301, 0.7957, 0.4319, 0.5780, 0.3931, 0.9269, 0.6401, 0.6530,\n",
       "         0.2649],\n",
       "        [0.7942, 0.7102, 0.0207, 0.4483, 0.4623, 0.4288, 0.6135, 0.4635, 0.3587,\n",
       "         0.8470],\n",
       "        [0.0658, 0.3038, 0.5583, 0.8279, 0.8095, 0.9491, 0.1631, 0.1156, 0.6326,\n",
       "         0.6004],\n",
       "        [0.5713, 0.8394, 0.8871, 0.8006, 0.9741, 0.7104, 0.8749, 0.9689, 0.0986,\n",
       "         0.8575]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why ramdom tensor?\n",
    "# random tensor are important because the way many neural network learn is that they start with tensor full of ramdom numbers and then adjust those ramdom number to better represent the data.\n",
    "#start with ramdom number -> look at data -> update random numbers -> look at data ->update\n",
    "\n",
    "random_tensor= torch.rand(10,10)\n",
    "random_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f018bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([[[0.3077, 0.4839],\n",
      "         [0.3913, 0.4452]],\n",
      "\n",
      "        [[0.2631, 0.9352],\n",
      "         [0.4007, 0.2030]],\n",
      "\n",
      "        [[0.1640, 0.2615],\n",
      "         [0.4463, 0.9973]]])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(random_tensor.ndim)\n",
    "random_tensor2= torch.rand(3,2,2)\n",
    "print(random_tensor2)\n",
    "print(random_tensor2.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe6549",
   "metadata": {},
   "source": [
    "IMAGE TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7df8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VVV important VVV\n",
    "# create a random tensor with similar shape to an image tensor\n",
    "\n",
    "random_image_tensor = torch.rand(size=(224,224,3))  # 224x224 image with 3 color channels (RGB) where 224 is the height and width of the image and size is the shape of the image tensor\n",
    "print(random_image_tensor.shape)\n",
    "# create a random tensor with similar shape to a multi-channel image tensor\n",
    "random_multi_channel_image_tensor = torch.rand(2, 3, 224, 224)  # 10 images, each with 3 channels and 224x224 pixels\n",
    "print(random_multi_channel_image_tensor.shape)\n",
    "print(random_multi_channel_image_tensor.ndim)\n",
    "print(random_multi_channel_image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a567fdd",
   "metadata": {},
   "source": [
    "Zeros, Ones and range and tensor like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5b826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# random tensor with zeros and ones\n",
    "random_zeros = torch.zeros(size=(3, 4))\n",
    "print(random_zeros)\n",
    "random_ones = torch.ones(size=(3, 4))\n",
    "print(random_ones)\n",
    "# creating a range of numbers\n",
    "random_range = torch.arange(0, 20, 1)  # start, end, step\n",
    "print(random_range)\n",
    "# creating tensor like another tensor but with zeros\n",
    "tensor_like = torch.zeros_like(random_range)  # creates a tensor of zeros with the same shape as random_tensor\n",
    "print(tensor_like)\n",
    "tensor_like2 = torch.ones_like(random_range)  # creates a tensor of ones with the same shape as random_tensor\n",
    "print(tensor_like2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b08f2",
   "metadata": {},
   "source": [
    "# Tensor datatypes\n",
    " **NOtes:** Tensor datatype is one of the 3 error we'll run into with PyTorch and deep learning\n",
    "  1. Tensor not right datatype\n",
    "  2. Tensor not right shape\n",
    "  3. tensor is no right device\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69845cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "torch.int32\n",
      "tensor([ 9., 36., 81.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# float 32 tensor\n",
    "float_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                            dtype=torch.float16, # we can use nonetype for float 32 tensor and used  for precision\n",
    "                            device=None,           # device=None,  # use 'cuda' for GPU or 'cpu' for CPU\n",
    "                            requires_grad=False)  # requires_grad=True if you want to track gradients for backpropagation\n",
    "print(float_tensor.dtype)\n",
    "\n",
    "# changing the datatype of a tensor\n",
    "float_tensor2= float_tensor.type(torch.int32)  # change to float32\n",
    "print(float_tensor2.dtype)\n",
    "\n",
    "ff= float_tensor2 * float_tensor\n",
    "print(ff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a51e38",
   "metadata": {},
   "source": [
    "### Getting information from tensor\n",
    "\n",
    "1. Tensor not right datatype - tensor.dtype eg: ff.dtype\n",
    "2. Tensor not right shape - tensor.shape\n",
    "3. tensor is no right device - tensor.device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a403523",
   "metadata": {},
   "source": [
    "## Manupulating tensors or tensor operations\n",
    "\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division (element-wise)\n",
    "* Matrix multiplication (@)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04a613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13, 14, 15])\n",
      "tensor([10, 20, 30, 40, 50])\n",
      "tensor([-9, -8, -7, -6, -5])\n",
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000])\n",
      "tensor([ 1,  4,  9, 16, 25])\n",
      "tensor([ 1,  4,  9, 16, 25])\n",
      "tensor([1, 0, 1, 0, 1])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[23, 34],\n",
      "        [31, 46]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "torch.Size([2, 3])\n",
      "2\n",
      "tensor([[ 14,  38],\n",
      "        [ 38, 110]])\n",
      "tensor([[ 1,  4,  9],\n",
      "        [25, 36, 49]])\n"
     ]
    }
   ],
   "source": [
    "sample= torch.tensor([1,2,3,4,5])\n",
    "print(sample + 10)\n",
    "print(sample * 10)\n",
    "print(sample - 10)\n",
    "print(sample / 10)\n",
    "print(sample ** 2)  # square each element\n",
    "print(torch.pow(sample, 2))  # another way to square each element and can do this this with addition, subtraction, multiplication, division\n",
    "print(sample % 2)  # modulus operation\n",
    "\n",
    "# Matrix multiplication or dot product\n",
    "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor2= torch.tensor([[5,6],[7,8]])\n",
    "print(tensor1 @ tensor2)  # matrix multiplication using @ operator\n",
    "print(tensor2 @ tensor1)\n",
    "# or using torch.matmul\n",
    "print(torch.matmul(tensor1, tensor2))  # matrix multiplication using torch.matmul\n",
    "# or using torch.mm\n",
    "print(torch.mm(tensor1, tensor2))  # matrix multiplication using torch.mm\n",
    "# element-wise multiplication\n",
    "print(tensor1 * tensor2)  # element-wise multiplication\n",
    "\n",
    "tensor3= torch.tensor([[1, 2, 3],[5,6,7]]) \n",
    "print(tensor3.shape)\n",
    "print(tensor3.ndim)\n",
    "print(torch.matmul(tensor3, tensor3.T))  # matrix multiplication with transpose\n",
    "print( tensor3 ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe9752",
   "metadata": {},
   "source": [
    "# find the min, max, mean, sum, etc ( tensor aggregation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7a169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor3:\n",
      "tensor([[33.,  7., 26., 21., 58., 40.],\n",
      "        [49., 61., 44., 58., 37., 62.],\n",
      "        [87., 57., 56., 99., 57., 21.],\n",
      "        [93., 58., 64., 73., 66., 60.],\n",
      "        [33., 84., 55., 42., 82., 26.]])\n",
      "torch.Size([5, 6])\n",
      "\n",
      " minimum value in the tensor:\n",
      "tensor(7.)\n",
      "\n",
      " maximum value in the tensor:\n",
      "tensor(99.)\n",
      "\n",
      " sum of all elements in the tensor:\n",
      "tensor(1609.)\n",
      "\n",
      " mean of all elements in the tensor:\n",
      "tensor(53.6333)\n",
      "\n",
      " standard deviation of all elements in the tensor:\n",
      "tensor(22.5381)\n",
      "\n",
      " variance of all elements in the tensor:\n",
      "tensor(507.9644)\n",
      "\n",
      " index of the minimum value in the tensor:\n",
      "tensor(1)\n",
      "\n",
      " index of the maximum value in the tensor:\n",
      "tensor(15)\n",
      "\n",
      " the minimum value in the tensor along dimension 0:\n",
      "torch.return_types.min(\n",
      "values=tensor([33.,  7., 26., 21., 37., 21.]),\n",
      "indices=tensor([0, 0, 0, 0, 1, 2]))\n",
      "\n",
      " the maximum value in the tensor along dimension 1:\n",
      "torch.return_types.max(\n",
      "values=tensor([58., 62., 99., 93., 84.]),\n",
      "indices=tensor([4, 5, 3, 0, 1]))\n",
      "\n",
      " the  median value in the tensor\n",
      "tensor(57.)\n"
     ]
    }
   ],
   "source": [
    "tensor3= torch.randint(2, 100, (5,6)) \n",
    "tensor3 = tensor3.type(torch.float32)  # convert to float32 for precision\n",
    "print(\"\\n tensor3:\")\n",
    "print(tensor3)\n",
    "print(tensor3.shape)\n",
    "\n",
    "print(\"\\n minimum value in the tensor:\")\n",
    "print(tensor3.min())  # minimum value in the tensor\n",
    "print(\"\\n maximum value in the tensor:\")\n",
    "print(tensor3.max())  # maximum value in the tensor\n",
    "print(\"\\n sum of all elements in the tensor:\")\n",
    "print(tensor3.sum())  # sum of all elements in the tensor\n",
    "print(\"\\n mean of all elements in the tensor:\")\n",
    "print(tensor3.mean())  # mean of all elements in the tensor\n",
    "print(\"\\n standard deviation of all elements in the tensor:\")\n",
    "print(tensor3.std())  # standard deviation of all elements in the tensor\n",
    "print(\"\\n variance of all elements in the tensor:\")\n",
    "print(tensor3.var())  # variance of all elements in the tensor\n",
    "print(\"\\n index of the minimum value in the tensor:\")\n",
    "print(tensor3.argmin())  # index of the minimum value in the tensor\n",
    "print(\"\\n index of the maximum value in the tensor:\")\n",
    "print(tensor3.argmax())  # index of the maximum value in the tensor\n",
    "print(\"\\n the minimum value in the tensor along dimension 0:\")\n",
    "print(tensor3.min(dim=0))  # index of the minimum value in the tensor along dimension 0\n",
    "print(\"\\n the maximum value in the tensor along dimension 1:\")\n",
    "print(tensor3.max(dim=1))  # index of the maximum value in the tensor along dimension 1\n",
    "print(\"\\n the  median value in the tensor\")\n",
    "print(tensor3.median())  # median value in the tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e7e2c",
   "metadata": {},
   "source": [
    "# Reshaping, stacking,  squeezing and unsqueezing\n",
    "\n",
    "* Reshaping= reshapes an input tensor to a defined shape\n",
    "* View -  return a view of an input tensor of certain shape but keep the same memory as the orginal tensor\n",
    "* Stacking - combine multiple tensors on the top of each other (vstack) or side by side (hstack)\n",
    "* Squeezing -  remove all \"1\" dimension from a tensor\n",
    "* Unsqueezing - add a\"1\" dimension to a targeted tensor\n",
    "* Permute - Return a view of the input with dimension permuted (swapped) in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "torch.Size([4, 3])\n",
      " \n",
      " reshaping the tensor to a different shape:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      " \n",
      " the original tensor: tensor([[15,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      " \n",
      " reshaped_tensor: tensor([[15,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "\n",
      " \n",
      " reshaping the tensor to a different shape using reshape:\n",
      "tensor([[15,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "torch.Size([2, 6])\n",
      " \n",
      " reshaping the tensor to a different shape using view:\n",
      "\n",
      " viewed_tensor after changing the first column to 20: tensor([[20,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "torch.Size([6, 2])\n",
      " \n",
      " original tensor after changing the first column of viewed_tensor:  tensor([[20,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      " \n",
      " reshaping the tensor to a different shape using flatten: to a 1D tensor\n",
      "tensor([20,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "tensor5= torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "print(tensor5)\n",
    "print(tensor5.shape)\n",
    "\n",
    "print(\" \\n reshaping the tensor to a different shape:\")\n",
    "reshaped_tensor = tensor5.reshape(3, 4)  # reshape to 3 rows and 4 columns\n",
    "print(reshaped_tensor)\n",
    "reshaped_tensor[0,0] = 15 # change the first column to 15\n",
    "print(f\" \\n the original tensor: {tensor5}\")\n",
    "print(f\" \\n reshaped_tensor: {reshaped_tensor}\")\n",
    "print(\"\\n \\n reshaping the tensor to a different shape using reshape:\")\n",
    "reshaped_tensor2 = tensor5.reshape(2, 6)  # reshape to 2 rows and 6 columns\n",
    "print(reshaped_tensor2)\n",
    "print(reshaped_tensor2.shape)\n",
    "\n",
    "print(\" \\n reshaping the tensor to a different shape using view:\")\n",
    "viewed_tensor = tensor5.view(6, 2)  # view to 3 rows and 4 columns\n",
    "viewed_tensor[0, 0] = 20  # change the first column to 20\n",
    "print(f\"\\n viewed_tensor after changing the first column to 20: {viewed_tensor}\")\n",
    "print(viewed_tensor.shape)\n",
    "print(\" \\n original tensor after changing the first column of viewed_tensor: \", tensor5)\n",
    "print(\" \\n reshaping the tensor to a different shape using flatten: to a 1D tensor\")\n",
    "flattened_tensor = tensor5.flatten()  # flatten the tensor to a 1D tensor\n",
    "print(flattened_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c8b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Stacked tensor along dimension 0:\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "\n",
      " Stacked tensor along dimension 1:\n",
      "tensor([[[1, 2],\n",
      "         [5, 6]],\n",
      "\n",
      "        [[3, 4],\n",
      "         [7, 8]]])\n",
      "\n",
      " Stacked tensor along dimension 2:\n",
      "tensor([[[1, 5],\n",
      "         [2, 6]],\n",
      "\n",
      "        [[3, 7],\n",
      "         [4, 8]]])\n",
      "\n",
      " Concatenated tensor along dimension 0:\n",
      "tensor([[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "\n",
      " Concatenated tensor along dimension 1:\n",
      "tensor([[ 1,  2,  9, 10],\n",
      "        [ 3,  4, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# stacking tensors\n",
    "tensor_a = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor_b = torch.tensor([[5, 6], [7, 8]])\n",
    "# stacking along dimension 0 (rows)\n",
    "stacked_tensor_0 = torch.stack([tensor_a, tensor_b], dim=0)  # stack along rows\n",
    "print(\"\\n Stacked tensor along dimension 0:\")\n",
    "print(stacked_tensor_0)\n",
    "# stacking along dimension 1 (columns)\n",
    "stacked_tensor_1 = torch.stack([tensor_a, tensor_b], dim=1)  # stack along columns\n",
    "print(\"\\n Stacked tensor along dimension 1:\")\n",
    "print(stacked_tensor_1)\n",
    "# stacking along dimension 2 (depth)\n",
    "stacked_tensor_2 = torch.stack([tensor_a, tensor_b], dim=2)  # stack along depth\n",
    "print(\"\\n Stacked tensor along dimension 2:\")\n",
    "print(stacked_tensor_2)\n",
    "# concatenating tensors\n",
    "tensor_c = torch.tensor([[9, 10], [11, 12]])\n",
    "# concatenating along dimension 0 (rows)\n",
    "concatenated_tensor_0 = torch.cat([tensor_a, tensor_c], dim=0)  # concatenate along rows\n",
    "print(\"\\n Concatenated tensor along dimension 0:\")\n",
    "print(concatenated_tensor_0)\n",
    "# concatenating along dimension 1 (columns)\n",
    "concatenated_tensor_1 = torch.cat([tensor_a, tensor_c], dim=1)  # concatenate along columns\n",
    "print(\"\\n Concatenated tensor along dimension 1:\")\n",
    "print(concatenated_tensor_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e750c",
   "metadata": {},
   "source": [
    "You started with this tensor:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "tensor5 = torch.tensor([[1, 2, 3, 4 , 5, 6, 7, 8, 9, 10, 11, 12]])\n",
    "This is a 2D tensor with shape:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "torch.Size([1, 12])\n",
    "Meaning:\n",
    "\n",
    "1 row\n",
    "\n",
    "12 columns\n",
    "\n",
    "âœ… 1. tensor5.unsqueeze(0)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "tensor_new = tensor5.unsqueeze(0)\n",
    "print(tensor_new.ndim)  # 3\n",
    "print(tensor_new.shape) # torch.Size([1, 1, 12])\n",
    "ðŸ“Œ What happened?\n",
    "\n",
    "You added a new dimension at index 0.\n",
    "\n",
    "The shape went from [1, 12] â†’ [1, 1, 12].\n",
    "\n",
    "Now it's a 3D tensor:\n",
    "\n",
    "1 batch\n",
    "\n",
    "1 row\n",
    "\n",
    "12 columns\n",
    "\n",
    "âœ… 2. tensor5.unsqueeze(2)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "tensor_new = tensor5.unsqueeze(2)\n",
    "print(tensor_new.ndim)  # 3\n",
    "print(tensor_new.shape) # torch.Size([1, 12, 1])\n",
    "ðŸ“Œ What happened?\n",
    "\n",
    "You added a new dimension at index 2 (after the 12).\n",
    "\n",
    "The shape changed: [1, 12] â†’ [1, 12, 1]\n",
    "\n",
    "So now it's:\n",
    "\n",
    "1 batch\n",
    "\n",
    "12 rows\n",
    "\n",
    "1 column per row\n",
    "\n",
    "Each number is now in its own little column vector.\n",
    "\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "tensor([[[ 1],\n",
    "         [ 2],\n",
    "         [ 3],\n",
    "         ...\n",
    "         [12]]])\n",
    "âœ… 3. tensor5.unsqueeze(1)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "tensor_new = tensor5.unsqueeze(1)\n",
    "print(tensor_new.ndim)  # 3\n",
    "print(tensor_new.shape) # torch.Size([1, 1, 12])\n",
    "ðŸ“Œ What happened?\n",
    "\n",
    "You added a new dimension at index 1 (between batch and columns).\n",
    "\n",
    "Shape went from [1, 12] â†’ [1, 1, 12], same as unsqueeze(0) in this specific case because there's only one row.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec3117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]]])\n",
      "3\n",
      "tensor([[[ 1],\n",
      "         [ 2],\n",
      "         [ 3],\n",
      "         [ 4],\n",
      "         [ 5],\n",
      "         [ 6],\n",
      "         [ 7],\n",
      "         [ 8],\n",
      "         [ 9],\n",
      "         [10],\n",
      "         [11],\n",
      "         [12]]])\n",
      "3\n",
      "tensor([[[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]]])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "tensor5= torch.tensor([[1, 2, 3, 4 , 5, 6, 7, 8, 9, 10, 11, 12]])\n",
    "tensor_new= tensor5.unsqueeze(0) # add a new dimension at index 0\n",
    "print(tensor_new.ndim)  # check the number of dimensions\n",
    "print(tensor_new)\n",
    "tensor_new= tensor5.unsqueeze(2) # add a new dimension at index 2\n",
    "print(tensor_new.ndim)  # check the number of dimensions\n",
    "print(tensor_new)\n",
    "tensor_new= tensor5.unsqueeze(1)  # add a new dimension at index 1\n",
    "print(tensor_new.ndim)  # check the number of dimensions\n",
    "tensor_old= tensor5.squeeze() # squeeeze the tensor only if it is squeezable\n",
    "print(tensor_new)\n",
    "print(tensor_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f96bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original tensor:\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "Shape of original tensor: torch.Size([1, 3, 3])\n",
      "\n",
      " Permuted tensor (swapped rows and columns):\n",
      "tensor([[[1],\n",
      "         [4],\n",
      "         [7]],\n",
      "\n",
      "        [[2],\n",
      "         [5],\n",
      "         [8]],\n",
      "\n",
      "        [[3],\n",
      "         [6],\n",
      "         [9]]])\n",
      "Shape of permuted tensor: torch.Size([3, 3, 1])\n",
      "tensor([[[ 30],\n",
      "         [ 66],\n",
      "         [102]],\n",
      "\n",
      "        [[ 36],\n",
      "         [ 81],\n",
      "         [126]],\n",
      "\n",
      "        [[ 42],\n",
      "         [ 96],\n",
      "         [150]]])\n"
     ]
    }
   ],
   "source": [
    "# Permutations\n",
    "tensor6 = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "print(\"\\n Original tensor:\")\n",
    "print(tensor6)\n",
    "print(\"Shape of original tensor:\", tensor6.shape)\n",
    "# Permuting dimensions\n",
    "permuted_tensor = tensor6.permute(2, 1, 0)  # swap rows and columns\n",
    "print(\"\\n Permuted tensor (swapped rows and columns):\")\n",
    "print(permuted_tensor)\n",
    "print(\"Shape of permuted tensor:\", permuted_tensor.shape)\n",
    "\n",
    "# original tensor consist of a single batch of 3x3 matrix but after permutation it becomes a 3 batch of 3x1 matrix\n",
    "\n",
    "print( tensor6 @ permuted_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168a33c",
   "metadata": {},
   "source": [
    "# Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with Pytorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c681a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original tensor x:\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "Shape of original tensor x: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "print(\"\\n Original tensor x:\")\n",
    "print(x)\n",
    "print(\"Shape of original tensor x:\", x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modified tensor x after changing the second row to 100:\n",
      "tensor([[[  1, 100,   3],\n",
      "         [  4, 100,   6],\n",
      "         [  7, 100,   9]]])\n"
     ]
    }
   ],
   "source": [
    "x[:,:,1]= 100  # change the value of the second row to 100\n",
    "print(\"\\n Modified tensor x after changing the second row to 100:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e05aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modified tensor x after changing the second row and second column to 200:\n",
      "tensor([[[  1,   2,   3],\n",
      "         [100, 100, 200],\n",
      "         [  7,   8,   9]]])\n"
     ]
    }
   ],
   "source": [
    "x[:, 1, 2] = 200  # change the value of the second row and second column to 200\n",
    "print(\"\\n Modified tensor x after changing the second row and second column to 200:\")\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3b073",
   "metadata": {},
   "source": [
    "# PyTorch and Numpy\n",
    "\n",
    "Numpy is a popular scientific python numerical computing library\n",
    "\n",
    "and because of this, Pytorch has functionality to interact withit\n",
    "\n",
    "* Data in NUmpy, want in Pytorch tensor -> 'torch.from_numpy(ndarray)'\n",
    "* Pytorch tensor -> NUmpy -> torch.Tensor.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "640323b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.] tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]) torch.float32\n",
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "\n",
      " \n",
      "Numpy array before change: (array([1., 2., 3., 4., 5.], dtype=float32), dtype('float32'))\n",
      "Tensor after changing the first element: tensor([100., 100., 100., 100., 100.])\n",
      "Numpy array after changing the first element of the tensor: [100. 100. 100. 100. 100.]\n"
     ]
    }
   ],
   "source": [
    "# Numpy array to tensor\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "array= np.array(range(1,11), dtype=np.float32)  # create a numpy array with float32 data type\n",
    "print(array)\n",
    "\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "print(array, tensor, tensor.dtype)\n",
    "\n",
    "print(torch.arange(1,10).type(torch.float32))  # create a tensor with float32 data type\n",
    "\n",
    "\n",
    "# Tensor to Numpy array\n",
    "tensorr = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)  # create a tensor with float32 data type\n",
    "numpy_array = tensorr.numpy()  # convert tensor to numpy array\n",
    "print(f\"\\n \\nNumpy array before change: {numpy_array, numpy_array.dtype}\")\n",
    "\n",
    "# changing the data in numpy array will not change the data in the tensor\n",
    "tensorr[:] = 100  # change the first element of the tensor\n",
    "print(\"Tensor after changing the first element:\", tensorr)\n",
    "print(\"Numpy array after changing the first element of the tensor:\", numpy_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b33b2b",
   "metadata": {},
   "source": [
    "# Reproducibility\n",
    "Trying to take random out of random\n",
    "\n",
    "In short how a neural network learns:\n",
    "\" Start with random number -> tensor operation -> update random numbers to try and make them better representation of the data -> again -> again -> again........\"\n",
    "\n",
    "To reduce the randomness in neural network and PyTorch comes the concept of a **random seed**.\n",
    "\n",
    "Essentially what the random seed does is \"flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6ca5959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random tensor 1:\n",
      "tensor([[0.0360, 0.4702, 0.0836, 0.4923],\n",
      "        [0.0704, 0.6059, 0.6124, 0.5387],\n",
      "        [0.5091, 0.5222, 0.8164, 0.7432]])\n",
      "\n",
      " Random tensor 2:\n",
      "tensor([[0.9152, 0.6875, 0.5310, 0.1687],\n",
      "        [0.1298, 0.7734, 0.8088, 0.8516],\n",
      "        [0.5172, 0.3096, 0.8823, 0.6121]])\n",
      "\n",
      " tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "random1= torch.rand(3,4)\n",
    "random2= torch.rand(3,4)\n",
    "\n",
    "print(\"\\n Random tensor 1:\")\n",
    "print(random1)\n",
    "print(\"\\n Random tensor 2:\")\n",
    "print(random2)\n",
    "print(\"\\n\", random1 == random2)  # check if the two tensors are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "55fc7df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random tensor 1 with seed 42:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      " Random tensor 2 with seed 42:\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "\n",
      " Random tensor 3 with seed 42:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      " Random tensor 4 with seed 42:\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "\n",
      " Random tensor 4 with seed 43:\n",
      "tensor([[0.4540, 0.1965, 0.9210, 0.3462],\n",
      "        [0.1481, 0.0858, 0.5909, 0.0659],\n",
      "        [0.7476, 0.6253, 0.9392, 0.1338]])\n"
     ]
    }
   ],
   "source": [
    "# lets' make some random but reproducible tensors\n",
    "torch.manual_seed(42)  # set the random seed for reproducibility\n",
    "random_tensor1 = torch.rand(3, 4)\n",
    "random_tensor2 = torch.rand(3, 4)\n",
    "print(\"\\n Random tensor 1 with seed 42:\")\n",
    "print(random_tensor1)\n",
    "print(\"\\n Random tensor 2 with seed 42:\")\n",
    "print(random_tensor2)\n",
    "# setting the random seed again will give the same random tensor\n",
    "torch.manual_seed(42)  # set the random seed for reproducibility\n",
    "random_tensor3 = torch.rand(3, 4)\n",
    "random_tensor4 = torch.rand(3, 4)\n",
    "print(\"\\n Random tensor 3 with seed 42:\")\n",
    "print(random_tensor3)\n",
    "print(\"\\n Random tensor 4 with seed 42:\")\n",
    "print(random_tensor4)\n",
    "# setting the random seed to a different value will give a different random tensor\n",
    "torch.manual_seed(43)  # set the random seed to a different value\n",
    "random_tensor5 = torch.rand(3, 4)\n",
    "print(\"\\n Random tensor 4 with seed 43:\")\n",
    "print(random_tensor5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d4fde",
   "metadata": {},
   "source": [
    "# GPU\n",
    "runing tensor and pytorch objects on the GPUs (making fater computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2082016",
   "metadata": {},
   "source": [
    "1. Getting a GPU\n",
    "2. Easiest way to get a GPU is to use Google Colab, which provides free access to GPUs.\n",
    "2. Use your own GPU - takes a liitle bit of setup and requires the investment of purchasing a GPU.\n",
    "3. Use a cloud provider - such as AWS, Azure, or GCP, which provide access to GPUs for a fee.\n",
    "4. Use a local machine with a GPU - if you have a local machine with a GPU, you can use it for training your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d663bc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 21 08:47:50 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.80                 Driver Version: 576.80         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce 940M          WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P0            N/A  /  200W |       0MiB /   2048MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be4e6b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
      "2.7.1+cpu\n",
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#python.version\n",
    "import sys\n",
    "print(sys.version)  # print the python version\n",
    "# torch.version\n",
    "import torch\n",
    "print(torch.__version__)  # print the torch version\n",
    "# torch.cuda.is_available()\n",
    "print(torch.cuda.is_available())  # check if CUDA is available\n",
    "# torch.cuda.device_count()\n",
    "print(torch.cuda.device_count())  # print the number of CUDA devices available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52aa0d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daba5e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor on device: tensor([1, 2, 3, 4, 5])\n",
      "GPU not available, tensor remains on CPU: tensor([1, 2, 3, 4, 5])\n",
      "CUDA is not available, using CPU instead\n",
      "Number of available GPUs: 0\n",
      "Current GPU name: No GPU available\n"
     ]
    }
   ],
   "source": [
    "tensor= torch.tensor([1, 2, 3, 4, 5], device= device)\n",
    "print(\"Tensor on device:\", tensor)\n",
    "# Move tensor to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor_gpu = tensor.to(device)\n",
    "    print(\"Tensor moved to GPU:\", tensor_gpu)\n",
    "else:\n",
    "    print(\"GPU not available, tensor remains on CPU:\", tensor)\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU instead\")\n",
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)\n",
    "# Get the name of the current GPU\n",
    "gpu_name = torch.cuda.get_device_name(0) if num_gpus > 0 else \"No GPU available\"\n",
    "print(\"Current GPU name:\", gpu_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
